#!/usr/bin/env python3
"""
FTP â†’ iCloud Photos ì‹¤ì‹œê°„ ë™ê¸°í™” ì‹œìŠ¤í…œ
Sony ì¹´ë©”ë¼ â†’ FTP â†’ Photos ì•± â†’ iCloud ìë™ ì—…ë¡œë“œ

íŠ¹ì§•:
- ì‹¤ì‹œê°„ íŒŒì¼ ê°ì§€ (watchdog)
- ì›ë³¸ íŒŒì¼ ë³´ì¡´ (ë³µì‚¬ë§Œ ìˆ˜í–‰)
- ì¤‘ë³µ ë°©ì§€ (SQLite ê¸°ë°˜ ì´ë ¥ ê´€ë¦¬)
- ë°°ì¹˜ ì—…ë¡œë“œ (ìˆœì°¨ ì²˜ë¦¬)
- iCloud ë™ê¸°í™” ê°•ì œ ì‹¤í–‰
"""

import os
import sys
import time
import hashlib
import sqlite3
import subprocess
import logging
from pathlib import Path
from datetime import datetime
from typing import Set, List, Dict, Optional
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import threading
import queue

class FTPiCloudPhotoSync:
    def __init__(self):
        # ê²½ë¡œ ì„¤ì •
        self.ftp_root = Path("/Volumes/990 PRO 2TB/FTP")
        self.project_dir = Path("/Volumes/990 PRO 2TB/GM/01_Projects/FTP-iCloud-Photos-Sync")
        self.db_path = self.project_dir / "sync_history.db"
        self.log_dir = Path("/Volumes/990 PRO 2TB/GM/logs")
        
        # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹
        self.supported_extensions = {
            '.jpg', '.jpeg', '.png', '.heic', '.heif',  # ì‚¬ì§„
            '.mov', '.mp4', '.avi', '.mkv'  # ë™ì˜ìƒ
        }
        
        # ì—…ë¡œë“œ í ë° ìƒíƒœ
        self.upload_queue = queue.Queue()
        self.processing = False
        self.batch_size = 10  # ìµœëŒ€ 10ì¥ì”© ë°°ì¹˜ ì²˜ë¦¬ (Photos ì•± ë¶€í•˜ ë°©ì§€)
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        
        self.logger.info("ğŸ¯ FTP â†’ iCloud Photos ë™ê¸°í™” ì‹œìŠ¤í…œ ì‹œì‘")

    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        self.log_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_dir / 'ftp_icloud_sync.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def _init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        self.project_dir.mkdir(exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS sync_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    file_path TEXT UNIQUE NOT NULL,
                    file_size INTEGER NOT NULL,
                    file_hash TEXT NOT NULL,
                    upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    status TEXT DEFAULT 'completed'
                )
            ''')
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_file_hash ON sync_history(file_hash)
            ''')
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_file_path ON sync_history(file_path)
            ''')

    def _get_file_hash(self, file_path: Path) -> str:
        """íŒŒì¼ í•´ì‹œê°’ ê³„ì‚° (ì¤‘ë³µ ê°ì§€ìš©) - ì„±ëŠ¥ ìµœì í™”"""
        try:
            # íŒŒì¼ í¬ê¸°ì™€ ìˆ˜ì • ì‹œê°„ì„ ì¡°í•©í•œ ë¹ ë¥¸ í•´ì‹œ ìƒì„±
            stat = file_path.stat()
            file_info = f"{file_path.name}_{stat.st_size}_{stat.st_mtime}"
            return hashlib.md5(file_info.encode()).hexdigest()
        except Exception as e:
            self.logger.error(f"âŒ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨ {file_path}: {e}")
            return ""

    def _is_duplicate(self, file_path: Path, file_size: int, file_hash: str) -> bool:
        """ì¤‘ë³µ íŒŒì¼ ì²´í¬"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM sync_history WHERE file_hash = ? OR file_path = ?",
                    (file_hash, str(file_path))
                )
                return cursor.fetchone()[0] > 0
        except Exception as e:
            self.logger.error(f"âŒ ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {e}")
            return False

    def _close_photos_error_dialogs(self):
        """Photos ì•± ì˜¤ë¥˜ ë‹¤ì´ì–¼ë¡œê·¸ ìë™ ë‹«ê¸°"""
        try:
            applescript = '''
            tell application "System Events"
                tell process "Photos"
                    repeat with theWindow in windows
                        try
                            if exists button "í™•ì¸" of theWindow then
                                click button "í™•ì¸" of theWindow
                            end if
                        end try
                    end repeat
                end tell
            end tell
            '''
            subprocess.run(['osascript', '-e', applescript], capture_output=True, timeout=5)
        except:
            pass

    def _add_batch_to_photos_app(self, file_paths: List[Path]) -> int:
        """Photos ì•±ì— ë°°ì¹˜ë¡œ íŒŒì¼ ì¶”ê°€ - ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"""
        max_retries = 2
        
        for retry in range(max_retries):
            try:
                # ì˜¤ë¥˜ì°½ ë‹«ê¸°
                self._close_photos_error_dialogs()
                
                # íŒŒì¼ ê²½ë¡œë“¤ì„ AppleScript ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                file_list = ", ".join([f'POSIX file "{fp}"' for fp in file_paths])
                
                if retry == 0:
                    self.logger.info(f"ğŸ“¤ {len(file_paths)}ê°œ íŒŒì¼ì„ 1ë²ˆì˜ ìš”ì²­ìœ¼ë¡œ ì—…ë¡œë“œ...")
                else:
                    self.logger.info(f"ğŸ”„ ì¬ì‹œë„ {retry}/{max_retries-1}: {len(file_paths)}ê°œ íŒŒì¼ ì—…ë¡œë“œ...")
                
                applescript = f'''
                tell application "Photos"
                    import {{{file_list}}} skip check duplicates yes
                end tell
                '''
                
                result = subprocess.run(
                    ['osascript', '-e', applescript],
                    capture_output=True,
                    text=True,
                    timeout=60  # 1ë¶„ìœ¼ë¡œ ë‹¨ì¶•
                )
                
                # ì—…ë¡œë“œ í›„ ì˜¤ë¥˜ì°½ ì²´í¬ ë° ë‹«ê¸°
                import time
                time.sleep(1)
                self._close_photos_error_dialogs()
                
                if result.returncode == 0:
                    self.logger.info(f"âœ… Photos ì•± ë°°ì¹˜ ì¶”ê°€ ì™„ë£Œ: {len(file_paths)}ê°œ íŒŒì¼")
                    return len(file_paths)
                else:
                    self.logger.warning(f"âš ï¸ ì‹œë„ {retry+1} ì‹¤íŒ¨: {result.stderr}")
                    if retry < max_retries - 1:
                        time.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                        
            except Exception as e:
                self.logger.warning(f"âš ï¸ ì‹œë„ {retry+1} ì˜¤ë¥˜: {e}")
                if retry < max_retries - 1:
                    import time
                    time.sleep(2)
        
        self.logger.error(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {[f.name for f in file_paths]}")
        return 0

    def _trigger_icloud_sync(self) -> bool:
        """iCloud Photos ë™ê¸°í™” ê°•ì œ ì‹¤í–‰"""
        try:
            # cloudphotod í”„ë¡œì„¸ìŠ¤ì— SIGUSR1 ì‹ í˜¸ ì „ì†¡ (ë™ê¸°í™” íŠ¸ë¦¬ê±°)
            result = subprocess.run(
                ['killall', '-USR1', 'cloudphotod'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                self.logger.info("ğŸ”„ iCloud Photos ë™ê¸°í™” íŠ¸ë¦¬ê±°ë¨")
                return True
            else:
                # ëŒ€ì•ˆ: Photos ì•± ì¬ì‹œì‘
                subprocess.run(['killall', 'Photos'], capture_output=True)
                time.sleep(2)
                subprocess.run(['open', '-a', 'Photos'], capture_output=True)
                self.logger.info("ğŸ”„ Photos ì•± ì¬ì‹œì‘ìœ¼ë¡œ ë™ê¸°í™” ìœ ë„")
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ iCloud ë™ê¸°í™” íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return False

    def _record_upload(self, file_path: Path, file_size: int, file_hash: str):
        """ì—…ë¡œë“œ ì´ë ¥ ê¸°ë¡"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    "INSERT OR REPLACE INTO sync_history (file_path, file_size, file_hash) VALUES (?, ?, ?)",
                    (str(file_path), file_size, file_hash)
                )
                self.logger.debug(f"ğŸ“ ì—…ë¡œë“œ ì´ë ¥ ê¸°ë¡: {file_path.name}")
        except Exception as e:
            self.logger.error(f"âŒ ì´ë ¥ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    def _process_file(self, file_path: Path) -> bool:
        """ê°œë³„ íŒŒì¼ ì²˜ë¦¬"""
        try:
            # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
            if not file_path.exists() or file_path.stat().st_size == 0:
                self.logger.warning(f"âš ï¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¹„ì–´ìˆìŒ: {file_path}")
                return False
            
            # ì§€ì›ë˜ëŠ” í˜•ì‹ì¸ì§€ í™•ì¸
            if file_path.suffix.lower() not in self.supported_extensions:
                self.logger.debug(f"ğŸš« ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹: {file_path}")
                return False
            
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            file_size = file_path.stat().st_size
            file_hash = self._get_file_hash(file_path)
            
            if not file_hash:
                return False
            
            # ì¤‘ë³µ ì²´í¬
            # ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™” - ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
            
            # ê°œë³„ íŒŒì¼ì€ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê²€ì¦ë§Œ
            return True
                
        except Exception as e:
            self.logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {e}")
            return False

    def _batch_processor(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ì›Œì»¤"""
        while True:
            try:
                # íì—ì„œ íŒŒì¼ë“¤ ìˆ˜ì§‘ (ìµœëŒ€ batch_sizeë§Œí¼)
                files_to_process = []
                
                # ì²« ë²ˆì§¸ íŒŒì¼ ëŒ€ê¸° (ë¸”ë¡œí‚¹) - íŒŒì¼ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì²˜ë¦¬
                try:
                    first_file = self.upload_queue.get(timeout=2)
                    files_to_process.append(first_file)
                except queue.Empty:
                    continue
                
                # ì¶”ê°€ íŒŒì¼ë“¤ ìˆ˜ì§‘ (ë…¼ë¸”ë¡œí‚¹) - ìˆëŠ” ë§Œí¼ë§Œ ìµœëŒ€ 10ì¥ê¹Œì§€
                while len(files_to_process) < self.batch_size:
                    try:
                        file_path = self.upload_queue.get_nowait()
                        files_to_process.append(file_path)
                    except queue.Empty:
                        break  # ë” ì´ìƒ íŒŒì¼ì´ ì—†ìœ¼ë©´ í˜„ì¬ íŒŒì¼ë“¤ë¡œ ë°”ë¡œ ì²˜ë¦¬
                
                if files_to_process:
                    self.processing = True
                    self.logger.info(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(files_to_process)}ê°œ íŒŒì¼ (ëŒ€ê¸°í•˜ì§€ ì•Šê³  ì¦‰ì‹œ ì²˜ë¦¬)")
                    
                    # íŒŒì¼ë“¤ ìˆœì°¨ ì²˜ë¦¬
                    success_count = 0
                    for file_path in files_to_process:
                        if self._process_file(file_path):
                            success_count += 1
                    
                    # ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ í›„ iCloud ë™ê¸°í™” íŠ¸ë¦¬ê±°
                    if success_count > 0:
                        self.logger.info(f"ğŸ¯ ë°°ì¹˜ ì™„ë£Œ: {success_count}/{len(files_to_process)}ê°œ ì„±ê³µ")
                            
                    self.processing = False
                    
                    # í ì™„ë£Œ ì‹ í˜¸
                    for _ in files_to_process:
                        self.upload_queue.task_done()
                        
            except Exception as e:
                self.logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                self.processing = False
                time.sleep(5)

    def scan_existing_files(self) -> List[Path]:
        """ê¸°ì¡´ íŒŒì¼ë“¤ì„ ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ìŠ¤ìº” (ëª¨ë“  í•˜ìœ„ í´ë” í¬í•¨) - ì„±ëŠ¥ ìµœì í™”"""
        self.logger.info("ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
        self.logger.info(f"ğŸ” ê²€ìƒ‰ ê²½ë¡œ: {self.ftp_root}")
        self.logger.info(f"ğŸ“ ì§€ì› í˜•ì‹: {', '.join(self.supported_extensions)}")
        
        existing_files = []
        scanned_folders = set()
        total_files_found = 0
        processed_count = 0
        
        # ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìŠ¤ìº”
        for file_path in self.ftp_root.rglob("*"):
            if file_path.is_file():
                total_files_found += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if total_files_found % 100 == 0:
                    self.logger.info(f"â³ ìŠ¤ìº” ì§„í–‰: {total_files_found}ê°œ íŒŒì¼ ê²€ì‚¬ ì¤‘...")
                
                # í´ë” ì¶”ì 
                folder = str(file_path.parent)
                if folder not in scanned_folders:
                    scanned_folders.add(folder)
                    self.logger.info(f"ğŸ“ í´ë” ìŠ¤ìº”: {file_path.parent.name}")
                
                # ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ í™•ì¸
                if file_path.suffix.lower() in self.supported_extensions:
                    try:
                        processed_count += 1
                        # ë¹ ë¥¸ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                        stat = file_path.stat()
                        file_size = stat.st_size
                        file_hash = self._get_file_hash(file_path)
                        
                        if True:  # ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™”
                            existing_files.append({
                                'path': file_path,
                                'mtime': stat.st_mtime,
                                'size': file_size,
                                'hash': file_hash
                            })
                            # 10ê°œì”© ë°œê²¬í•  ë•Œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
                            if len(existing_files) % 10 == 0:
                                self.logger.info(f"âœ… ìƒˆ íŒŒì¼ {len(existing_files)}ê°œ ë°œê²¬...")
                        
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path.name}: {e}")
        
        # ìˆ˜ì • ì‹œê°„ìˆœ ì •ë ¬ (ê³¼ê±° â†’ ìµœê·¼)
        existing_files.sort(key=lambda x: x['mtime'])
        
        self.logger.info(f"ğŸ“Š ìŠ¤ìº” ì™„ë£Œ:")
        self.logger.info(f"   ğŸ“ ìŠ¤ìº”ëœ í´ë”: {len(scanned_folders)}ê°œ")
        self.logger.info(f"   ğŸ“„ ì „ì²´ íŒŒì¼: {total_files_found}ê°œ")
        self.logger.info(f"   ğŸ¯ ë¯¸ë””ì–´ íŒŒì¼: {processed_count}ê°œ")
        self.logger.info(f"   ğŸ“¤ ì—…ë¡œë“œ ëŒ€ìƒ: {len(existing_files)}ê°œ")
        
        return [f['path'] for f in existing_files]

    def process_existing_files_batch(self, batch_size: int = 3):
        """ê¸°ì¡´ íŒŒì¼ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        existing_files = self.scan_existing_files()
        
        if not existing_files:
            self.logger.info("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        total_files = len(existing_files)
        self.logger.info(f"ğŸš€ {total_files}ê°œ íŒŒì¼ ë°°ì¹˜ ì—…ë¡œë“œ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        processed = 0
        success_count = 0
        
        for i in range(0, total_files, batch_size):
            batch = existing_files[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_files + batch_size - 1) // batch_size
            
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ íŒŒì¼)")
            
            batch_success = 0
            for file_path in batch:
                self.logger.info(f"ğŸ“¤ ì—…ë¡œë“œ: {file_path.name} ({file_path.parent.name}/)")
                if self._process_file(file_path):
                    batch_success += 1
                    success_count += 1
                processed += 1
                
            
            # ë°°ì¹˜ ì™„ë£Œ í›„ iCloud ë™ê¸°í™”
            if batch_success > 0:
                self.logger.info(f"ğŸ¯ ë°°ì¹˜ {batch_num} ì™„ë£Œ: {batch_success}/{len(batch)}ê°œ ì„±ê³µ")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = (processed / total_files) * 100
                self.logger.info(f"ğŸ“ˆ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({processed}/{total_files})")
                
            
        # ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ í›„ í•œë²ˆì— iCloud ë™ê¸°í™”
        if success_count > 0:
            self.logger.info(f"ğŸ”„ ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ! iCloud ë™ê¸°í™” ì‹œì‘...")
            self._trigger_icloud_sync()
            
        self.logger.info(f"ğŸ‰ ê¸°ì¡´ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ì„±ê³µ: {success_count}/{total_files}ê°œ")

class FTPFileHandler(FileSystemEventHandler):
    """FTP í´ë” íŒŒì¼ ë³€ê²½ ê°ì§€"""
    
    def __init__(self, sync_manager: FTPiCloudPhotoSync):
        self.sync_manager = sync_manager
        self.logger = sync_manager.logger
        
    def on_created(self, event):
        """ìƒˆ íŒŒì¼ ìƒì„± ê°ì§€"""
        if event.is_directory:
            return
            
        file_path = Path(event.src_path)
        
        # íŒŒì¼ ìƒì„± ì™„ë£Œ ëŒ€ê¸° (ì¹´ë©”ë¼ ì—…ë¡œë“œê°€ ì™„ë£Œë  ë•Œê¹Œì§€)
        self._wait_for_file_complete(file_path)
        
        # ì§€ì›ë˜ëŠ” í˜•ì‹ì¸ì§€ í™•ì¸
        if file_path.suffix.lower() in self.sync_manager.supported_extensions:
            self.logger.info(f"ğŸ“ ìƒˆ íŒŒì¼ ê°ì§€: {file_path.name}")
            # íì— ì¶”ê°€
            self.sync_manager.upload_queue.put(file_path)
    
    def _wait_for_file_complete(self, file_path: Path, max_wait: int = 30):
        """íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°"""
        last_size = 0
        stable_count = 0
        
        for _ in range(max_wait):
            try:
                if file_path.exists():
                    current_size = file_path.stat().st_size
                    if current_size == last_size and current_size > 0:
                        stable_count += 1
                        if stable_count >= 3:  # 3ì´ˆê°„ í¬ê¸°ê°€ ì•ˆì •ë˜ë©´ ì™„ë£Œë¡œ íŒë‹¨
                            break
                    else:
                        stable_count = 0
                    last_size = current_size
                time.sleep(1)
            except:
                time.sleep(1)

    def scan_existing_files(self) -> List[Path]:
        """ê¸°ì¡´ íŒŒì¼ë“¤ì„ ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ìŠ¤ìº” (ëª¨ë“  í•˜ìœ„ í´ë” í¬í•¨)"""
        self.logger.info("ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
        self.logger.info(f"ğŸ” ê²€ìƒ‰ ê²½ë¡œ: {self.ftp_root}")
        self.logger.info(f"ğŸ“ ì§€ì› í˜•ì‹: {', '.join(self.supported_extensions)}")
        
        existing_files = []
        scanned_folders = set()
        total_files_found = 0
        
        # ëª¨ë“  í•˜ìœ„ í´ë”ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ìŠ¤ìº”
        for file_path in self.ftp_root.rglob("*"):
            if file_path.is_file():
                total_files_found += 1
                
                # í´ë” ì¶”ì 
                folder = str(file_path.parent)
                if folder not in scanned_folders:
                    scanned_folders.add(folder)
                    self.logger.info(f"ğŸ“ í´ë” ìŠ¤ìº”: {file_path.parent.name}")
                
                # ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ í™•ì¸
                if file_path.suffix.lower() in self.supported_extensions:
                    try:
                        # ì¤‘ë³µ ì²´í¬
                        file_size = file_path.stat().st_size
                        file_hash = self._get_file_hash(file_path)
                        
                        if True:  # ì¤‘ë³µ ì²´í¬ ë¹„í™œì„±í™”
                            existing_files.append({
                                'path': file_path,
                                'mtime': file_path.stat().st_mtime,
                                'size': file_size,
                                'hash': file_hash
                            })
                            self.logger.debug(f"âœ… ìƒˆ íŒŒì¼ ë°œê²¬: {file_path.name}")
                        else:
                            self.logger.debug(f"ğŸ”„ ì¤‘ë³µ íŒŒì¼ ê±´ë„ˆëœ€: {file_path.name}")
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")
                else:
                    self.logger.debug(f"ğŸš« ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹: {file_path.name}")
        
        # ìˆ˜ì • ì‹œê°„ìˆœ ì •ë ¬ (ê³¼ê±° â†’ ìµœê·¼)
        existing_files.sort(key=lambda x: x['mtime'])
        
        self.logger.info(f"ğŸ“Š ìŠ¤ìº” ê²°ê³¼:")
        self.logger.info(f"   ğŸ“ ìŠ¤ìº”ëœ í´ë”: {len(scanned_folders)}ê°œ")
        self.logger.info(f"   ğŸ“„ ì „ì²´ íŒŒì¼: {total_files_found}ê°œ")
        self.logger.info(f"   ğŸ¯ ì—…ë¡œë“œ ëŒ€ìƒ: {len(existing_files)}ê°œ")
        
        # ìŠ¤ìº”ëœ í´ë” ëª©ë¡ ì¶œë ¥
        for folder in sorted(scanned_folders):
            self.logger.info(f"   ğŸ“ {folder}")
        
        return [f['path'] for f in existing_files]

    def process_existing_files_batch(self, batch_size: int = 10):
        """ê¸°ì¡´ íŒŒì¼ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        existing_files = self.scan_existing_files()
        
        if not existing_files:
            self.logger.info("âœ… ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ë™ê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        
        total_files = len(existing_files)
        self.logger.info(f"ğŸš€ {total_files}ê°œ íŒŒì¼ ë°°ì¹˜ ì—…ë¡œë“œ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})")
        
        processed = 0
        success_count = 0
        
        for i in range(0, total_files, batch_size):
            batch = existing_files[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_files + batch_size - 1) // batch_size
            
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ íŒŒì¼)")
            
            batch_success = 0
            for file_path in batch:
                self.logger.info(f"ğŸ“¤ ì—…ë¡œë“œ: {file_path.name} ({file_path.parent.name}/)")
                if self._process_file(file_path):
                    batch_success += 1
                    success_count += 1
                processed += 1
                
            
            # ë°°ì¹˜ ì™„ë£Œ í›„ iCloud ë™ê¸°í™”
            if batch_success > 0:
                self.logger.info(f"ğŸ¯ ë°°ì¹˜ {batch_num} ì™„ë£Œ: {batch_success}/{len(batch)}ê°œ ì„±ê³µ")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress = (processed / total_files) * 100
                self.logger.info(f"ğŸ“ˆ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({processed}/{total_files})")
                
            
        # ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ í›„ í•œë²ˆì— iCloud ë™ê¸°í™”
        if success_count > 0:
            self.logger.info(f"ğŸ”„ ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ! iCloud ë™ê¸°í™” ì‹œì‘...")
            self._trigger_icloud_sync()
            
        self.logger.info(f"ğŸ‰ ê¸°ì¡´ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ! ì„±ê³µ: {success_count}/{total_files}ê°œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ë™ê¸°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        sync_manager = FTPiCloudPhotoSync()
        
        # FTP í´ë” ì¡´ì¬ í™•ì¸
        if not sync_manager.ftp_root.exists():
            sync_manager.logger.error(f"âŒ FTP í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {sync_manager.ftp_root}")
            return 1
        
        # ëª…ë ¹í–‰ ì¸ìˆ˜ í™•ì¸
        if len(sys.argv) > 1 and sys.argv[1] == "--sync-existing":
            # ê¸°ì¡´ íŒŒì¼ ë™ê¸°í™” ëª¨ë“œ
            sync_manager.logger.info("ğŸ”„ ê¸°ì¡´ íŒŒì¼ ë™ê¸°í™” ëª¨ë“œ ì‹œì‘")
            sync_manager.process_existing_files_batch(batch_size=10)  # ë°°ì¹˜ í¬ê¸° 10ê°œë¡œ ì„¤ì •
            return 0
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘
        batch_thread = threading.Thread(target=sync_manager._batch_processor, daemon=True)
        batch_thread.start()
        sync_manager.logger.info("ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘ë¨")
        
        # ì‹œì‘ ì‹œ ê¸°ì¡´ íŒŒì¼ 1ê°œ ë°°ì¹˜ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸)
        existing_thread = threading.Thread(
            target=lambda: sync_manager.process_existing_files_batch(batch_size=1), 
            daemon=True
        )
        existing_thread.start()
        
        # íŒŒì¼ ì‹œìŠ¤í…œ ê°ì‹œ ì„¤ì •
        event_handler = FTPFileHandler(sync_manager)
        observer = Observer()
        observer.schedule(event_handler, str(sync_manager.ftp_root), recursive=True)
        
        # ê°ì‹œ ì‹œì‘
        observer.start()
        sync_manager.logger.info(f"ğŸ‘ï¸ FTP í´ë” ê°ì‹œ ì‹œì‘: {sync_manager.ftp_root}")
        sync_manager.logger.info("ğŸ›‘ ì¢…ë£Œ: Ctrl+C")
        
        try:
            while True:
                time.sleep(1)
                # ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥
                if sync_manager.upload_queue.qsize() > 0:
                    sync_manager.logger.info(f"ğŸ“‹ ëŒ€ê¸° ì¤‘ì¸ íŒŒì¼: {sync_manager.upload_queue.qsize()}ê°œ")
                
        except KeyboardInterrupt:
            sync_manager.logger.info("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ë°›ìŒ")
            
        observer.stop()
        observer.join()
        sync_manager.logger.info("âœ… FTP â†’ iCloud Photos ë™ê¸°í™” ì‹œìŠ¤í…œ ì¢…ë£Œ")
        return 0
        
    except Exception as e:
        logging.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())